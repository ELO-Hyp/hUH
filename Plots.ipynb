{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INITIALIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib as il\n",
    "from hypso import Hypso1, Hypso2\n",
    "import src.deh as deh\n",
    "il.reload(deh)\n",
    "\n",
    "HYPSO_HEIGHT    =1092\n",
    "HYPSO_WIDTH     =598\n",
    "HYPSO_BANDS     =112 \n",
    "wavelengths = [387.8475,  391.40405, 394.9594,  398.51355, 402.06647, 405.61816, 409.1686,\n",
    " 412.71786, 416.2659,  419.8127,  423.3583,  426.90268, 430.44586, 433.9878,\n",
    " 437.5285,  441.068,   444.6063,  448.14334, 451.67917, 455.2138,  458.7472,\n",
    " 462.2794,  465.81033, 469.3401,  472.86862, 476.3959,  479.922,   483.44687,\n",
    " 486.97052, 490.49295, 494.01416, 497.53415, 501.05292, 504.57047, 508.0868,\n",
    " 511.6019,  515.1158,  518.6285,  522.1399,  525.65015, 529.1592,  532.667,\n",
    " 536.1735,  539.6789,  543.18304, 546.686,   550.1876,  553.6881,  557.1874,\n",
    " 560.6854,  564.18225, 567.67786, 571.17224, 574.6654,  578.15735, 581.6481,\n",
    " 585.1376,  588.62585, 592.1129,  595.59875, 599.0834,  602.5668,  606.049,\n",
    " 609.52997, 613.0097,  616.4882,  619.9656,  623.44165, 626.9165,  630.39014,\n",
    " 633.8626,  637.3338,  640.80383, 644.2726,  647.7401,  651.2065,  654.6716,\n",
    " 658.1355,  661.59814, 665.05963, 668.5199,  671.9789,  675.4367,  678.89325,\n",
    " 682.34863, 685.8028,  689.25574, 692.7074,  696.1579,  699.6072,  703.05524,\n",
    " 706.502,   709.94763, 713.392,   716.8352,  720.27716, 723.7179,  727.1574,\n",
    " 730.5957,  734.0328,  737.4686,  740.90326, 744.3367,  747.76886, 751.1998,\n",
    " 754.6296,  758.0581,  761.4855,  764.91156, 768.3364,  771.7601,  775.1825,\n",
    " 778.60376, 782.02374, 785.4425,  788.8601,  792.2764,  795.6915,  799.10547,\n",
    " 802.5181 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPSO_1_NC_DIR  = r\"D:\\HYPSO_1_NC\"\n",
    "HYPSO_2_NC_DIR  = r\"D:\\HYPSO_2_NC\"\n",
    "DATA_DIR        = r\"D:\\Hierarchical Unmixing Label\\hUH\\data\"\n",
    "IMAGES_DIR      = DATA_DIR + r\"\\images\"\n",
    "DEH_DIR         = DATA_DIR + r\"\\deh_models\"\n",
    "LABELS_DIR      = DATA_DIR + r\"\\labels\"\n",
    "TREE_DIR        = DATA_DIR + r\"\\tree_models\"\n",
    "PRED_DIR        = DATA_DIR + r\"\\predictions\"\n",
    "BINARY_PRED_DIR = DATA_DIR + r\"\\binary_predictions\"\n",
    "DECODED_DIR     = DATA_DIR + r\"\\decoded_predictions\"\n",
    "# PIPELINE_DIR    = r\"\\\\wsl.localhost\\Ubuntu-24.04\\home\\lofty\\CODE\\onboard-pipeline-modules\"\n",
    "# BINARY_PRED_DIR = PIPELINE_DIR + r\"\\onboard_classification\\onboard_classification\\src\\data\\output\"\n",
    "# DECODED_DIR     = PIPELINE_DIR + r\"\\decoding\\decoded_output\"\n",
    "hUH_model_file='10img_16end_L1D_112_MACHI_stabelized_aa.h5'\n",
    "hUH_model_path=(os.path.join(DEH_DIR, hUH_model_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HYPSO 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1A_array = [\n",
    "    'yucatan2_2025-02-06T16-01-18Z-l1a_flat_L1A_120.npy',\n",
    "    'kemigawa_2024-12-17T01-01-32Z-l1a_flat_L1A_120.npy', \n",
    "    'chapala_2025-02-24T16-52-47Z-l1a_flat_L1A_120.npy',\n",
    "    'grizzlybay_2025-01-27T18-19-56Z-l1a_flat_L1A_120.npy',\n",
    "    'victoriaLand_2025-02-07T20-35-33Z-l1a_flat_L1A_120.npy',\n",
    "    'catala_2025-01-28T19-17-32Z-l1a_flat_L1A_120.npy',\n",
    "    'khnifiss_2025-02-12T11-05-35Z-l1a_flat_L1A_120.npy',\n",
    "    'menindee_2025-02-18T00-10-42Z-l1a_flat_L1A_120.npy',\n",
    "    'tampa_2024-11-12T15-31-55Z-l1a_flat_L1A_120.npy',\n",
    "    'falklandsatlantic_2024-12-18T13-25-18Z-l1a_flat_L1A_120.npy'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUH_labels=[\n",
    "    'yucatan2_2025-02-06T16-01-18Z-l1a_flat_L1D_112_MACHI_16end_labels.npy',\n",
    "    'kemigawa_2024-12-17T01-01-32Z-l1a_flat_L1D_112_MACHI_16end_labels.npy',\n",
    "    'chapala_2025-02-24T16-52-47Z-l1a_flat_L1D_112_MACHI_16end_labels.npy',\n",
    "    'grizzlybay_2025-01-27T18-19-56Z-l1a_flat_L1D_112_MACHI_16end_labels.npy',\n",
    "    'victoriaLand_2025-02-07T20-35-33Z-l1a_flat_L1D_112_MACHI_16end_labels.npy',\n",
    "    'catala_2025-01-28T19-17-32Z-l1a_flat_L1D_112_MACHI_16end_labels.npy',\n",
    "    'khnifiss_2025-02-12T11-05-35Z-l1a_flat_L1D_112_MACHI_16end_labels.npy',\n",
    "    'menindee_2025-02-18T00-10-42Z-l1a_flat_L1D_112_MACHI_16end_labels.npy',\n",
    "    'tampa_2024-11-12T15-31-55Z-l1a_flat_L1D_112_MACHI_16end_labels.npy',\n",
    "    'falklandsatlantic_2024-12-18T13-25-18Z-l1a_flat_L1D_112_MACHI_16end_labels.npy'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_predictions = [\n",
    "    'yucatan2_2025_02_06_pred.npy',\n",
    "    'kemigawa_2024_12_17_pred.npy',\n",
    "    'chapala_2025_02_24_pred.npy',\n",
    "    'grizzlybay_2025_01_27_pred.npy',\n",
    "    'victoriaLand_2025_02_07_pred.npy',\n",
    "    'catala_2025_01_28_pred.npy',\n",
    "    'khnifiss_2025_02_12_pred.npy',\n",
    "    'menindee_2025_02_18_pred.npy',\n",
    "    'tampa_2024_11_12_pred.npy',\n",
    "    'falklandsatlantic_2024_12_18_pred.npy'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_predictions = [\n",
    "    'caspiansea1_2025-04-08T07-11-56Z_16end.bin',\n",
    "    'tampa_2024-11-12T15-31-55Z_16end.bin',\n",
    "    'vancouver_2025-05-04T19-12-24Z_16end.bin',\n",
    "    'grizzlybay_2025-05-30T18-20-50Z_16end.bin'\n",
    "]\n",
    "decoded_predictions = [\n",
    "    'caspiansea1_2025-04-08T07-11-56Z_16end.npy',\n",
    "    'tampa_2024-11-12T15-31-55Z_16end.npy',\n",
    "    'vancouver_2025-05-04T19-12-24Z_16end.npy',\n",
    "    'grizzlybay_2025-05-30T18-20-50Z_16end.npy'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file          ='vancouver_2025-05-04T19-12-24Z-l1a_flat_L1D_112_MACHI.npy'\n",
    "raw_image_file      ='vancouver_2025-05-04T19-12-24Z-l1a_flat_L1A_120.npy'\n",
    "HUH_label_file      ='vancouver_2025-05-04T19-12-24Z-l1a_flat_L1D_112_MACHI_16end_labels.npy'\n",
    "SVM_pred_file       ='vancouver_2025_05_04_L1A_120_pred.npy'\n",
    "DECODED_pred_file   =\"vancouver_2025-05-04T19-12-24Z_16end.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file          ='caspiansea1_2025-04-08T07-11-56Z-l1a_flat_L1D_112_MACHI.npy'\n",
    "raw_image_file      ='caspiansea1_2025-04-08T07-11-56Z-l1a_flat_L1A_120.npy'\n",
    "HUH_label_file      ='caspiansea1_2025-04-08T07-11-56Z-l1a_flat_L1D_112_MACHI_16end_labels.npy'\n",
    "SVM_pred_file       ='caspiansea1_2025_04_08_pred.npy'\n",
    "DECODED_pred_file   =\"caspiansea1_2025-04-08T07-11-56Z_16end.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file          ='tampa_2024-11-12T15-31-55Z-l1a_flat_L1D_112_MACHI.npy'\n",
    "raw_image_file      ='tampa_2024-11-12T15-31-55Z-l1a_flat_L1A_120.npy'\n",
    "HUH_label_file      ='tampa_2024-11-12T15-31-55Z-l1a_flat_L1D_112_MACHI_16end_labels.npy'\n",
    "SVM_pred_file       ='tampa_2024_11_12_pred.npy'\n",
    "DECODED_pred_file   =\"tampa_2024-11-12T15-31-55Z_16end.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path          =os.path.join(IMAGES_DIR, image_file)\n",
    "raw_image_path      =os.path.join(IMAGES_DIR, raw_image_file)\n",
    "HUH_label_path      =os.path.join(LABELS_DIR, HUH_label_file)\n",
    "SVM_pred_path       =os.path.join(PRED_DIR, SVM_pred_file)\n",
    "DECODED_pred_path   =os.path.join(DECODED_DIR, DECODED_pred_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HYPSO 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H2_10_label_file='H2_10_L1D_112_MACHI_16end_labels.npy'\n",
    "H2_10_label_path=os.path.join(LABELS_DIR,H2_10_label_file)\n",
    "\n",
    "H2_10_L1A_120                 = np.load(os.path.join(IMAGES_DIR,'H2_10_L1A_120.npy'))\n",
    "H2_10_L1D_112_MACHI           = np.load(os.path.join(IMAGES_DIR,'H2_10_L1D_112_MACHI.npy'))\n",
    "H2_10_L1D_112_MACHI_labels    = np.load(os.path.join(LABELS_DIR,'H2_10_L1D_112_MACHI_16end_labels.npy'), allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H2_L1D_files = [\n",
    "    'yucatan1_2025-04-01_flat_L1D_112_H2_MACHI.npy',\n",
    "    'kemigawa_2025-01-22_flat_L1D_112_H2_MACHI.npy',\n",
    "    'chapala_2025-03-25_flat_L1D_112_H2_MACHI.npy',\n",
    "    'grizzlybay_2025-01-22_flat_L1D_112_H2_MACHI.npy',\n",
    "    'victoriaLand_2025-03-16_flat_L1D_112_H2_MACHI.npy',\n",
    "    'mjosa_2025-05-12_flat_L1D_112_H2_MACHI.npy',\n",
    "    'gobabeb_2025-04-25_flat_L1D_112_H2_MACHI.npy',\n",
    "    'menindee_2025-05-09_flat_L1D_112_H2_MACHI.npy',\n",
    "    'erie_2025-05-10_flat_L1D_112_H2_MACHI.npy',\n",
    "    'falklandsatlantic_2025-03-03_flat_L1D_112_H2_MACHI.npy'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H2_L1A_files = [\n",
    "    'yucatan1_2025-04-01_flat_L1A_120_H2.npy',\n",
    "    'kemigawa_2025-01-22_flat_L1A_120_H2.npy',\n",
    "    'chapala_2025-03-25_flat_L1A_120_H2.npy',\n",
    "    'grizzlybay_2025-01-22_flat_L1A_120_H2.npy',\n",
    "    'victoriaLand_2025-03-16_flat_L1A_120_H2.npy',\n",
    "    'mjosa_2025-05-12_flat_L1A_120_H2.npy',\n",
    "    'gobabeb_2025-04-25_flat_L1A_120_H2.npy',\n",
    "    'menindee_2025-05-09_flat_L1A_120_H2.npy',\n",
    "    'erie_2025-05-10_flat_L1A_120_H2.npy',\n",
    "    'falklandsatlantic_2025-03-03_flat_L1A_120_H2.npy'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H2_HUH_labels=[\n",
    "    'yucatan1_2025-04-01_flat_L1D_112_H2_MACHI_16end_labels.npy',\n",
    "    'kemigawa_2025-01-22_flat_L1D_112_H2_MACHI_16end_labels.npy',\n",
    "    'chapala_2025-03-25_flat_L1D_112_H2_MACHI_16end_labels.npy',\n",
    "    'grizzlybay_2025-01-22_flat_L1D_112_H2_MACHI_16end_labels.npy',\n",
    "    'victoriaLand_2025-03-16_flat_L1D_112_H2_MACHI_16end_labels.npy',\n",
    "    'mjosa_2025-05-12_flat_L1D_112_H2_MACHI_16end_labels.npy',\n",
    "    'gobabeb_2025-04-25_flat_L1D_112_H2_MACHI_16end_labels.npy',\n",
    "    'menindee_2025-05-09_flat_L1D_112_H2_MACHI_16end_labels.npy',\n",
    "    'erie_2025-05-10_flat_L1D_112_H2_MACHI_16end_labels.npy',\n",
    "    'falklandsatlantic_2025-03-03_flat_L1D_112_H2_MACHI_16end_labels.npy'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H2_SVM_predictions=[\n",
    "    'yucatan1_2025-04-01_flat_L1A_120_H2_16end_pred.npy',\n",
    "    'kemigawa_2025-01-22_flat_L1A_120_H2_16end_pred.npy',\n",
    "    'chapala_2025-03-25_flat_L1A_120_H2_16end_pred.npy',\n",
    "    'grizzlybay_2025-01-22_flat_L1A_120_H2_16end_pred.npy',\n",
    "    'victoriaLand_2025-03-16_flat_L1A_120_H2_16end_pred.npy',\n",
    "    'mjosa_2025-05-12_flat_L1A_120_H2_16end_pred.npy',\n",
    "    'gobabeb_2025-04-25_flat_L1A_120_H2_16end_pred.npy',\n",
    "    'menindee_2025-05-09_flat_L1A_120_H2_16end_pred.npy',\n",
    "    'erie_2025-05-10_flat_L1A_120_H2_16end_pred.npy',\n",
    "    'falklandsatlantic_2025-03-03_flat_L1A_120_H2_16end_pred.npy'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOTTING FUNCTIONS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discrete_colormap(n_classes=16, reverse=False):\n",
    "    \"\"\"\n",
    "    Create a discrete colormap with fixed colors for each class.\n",
    "    \"\"\"\n",
    "    # Get colors from viridis\n",
    "    viridis = plt.cm.viridis\n",
    "    # Create a fixed set of n_classes colors\n",
    "    if reverse:\n",
    "        colors = [viridis(1 - i/(n_classes-1)) for i in range(n_classes)]\n",
    "    else:\n",
    "        colors = [viridis(i/(n_classes-1)) for i in range(n_classes)]\n",
    "    # # Add transparent color for 0 (background)\n",
    "    # colors.insert(0, (0,0,0,0))\n",
    "    # Create discrete colormap\n",
    "    return plt.matplotlib.colors.ListedColormap(colors)\n",
    "\n",
    "def create_custom_colormap():\n",
    "    \"\"\"\n",
    "    Create a custom colormap with manually selected colors for 16 classes.\n",
    "    Colors are specified in RGB format (values between 0 and 1).\n",
    "    \"\"\"\n",
    "\n",
    "    colors = [\n",
    "        (0, 0.2, 0),          \n",
    "        (0, 0.25, 0),          \n",
    "        (0, 0.30, 0),           \n",
    "        (0, 0.35, 0),           \n",
    "        (0.80, 0.75, 0.57),           \n",
    "        (0, 0.2, 0.2),           \n",
    "        (0.75, 0.75, 0.75),          \n",
    "        (0.9, 0.9, 0.9),       \n",
    "        (0, 0, 0.3),       \n",
    "        (0, 0, 0.35),      \n",
    "        (0, 0, 0.4),      \n",
    "        (0, 0, 0.45),    \n",
    "        (0, 0, 0.5),      \n",
    "        (0, 0, 0.55),     \n",
    "        (0, 0, 0.6),\n",
    "        (1, 1, 1)        \n",
    "    ]\n",
    "    \n",
    "    # Create discrete colormap\n",
    "    return plt.matplotlib.colors.ListedColormap(colors)\n",
    "\n",
    "realistic_cmap = create_custom_colormap()\n",
    "\n",
    "discrete_cmap=create_discrete_colormap(16)\n",
    "\n",
    "custom_cmap = realistic_cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_path(path):\n",
    "    \"\"\"\n",
    "    Load a dictionary or array from a .npy file\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dict_path : str\n",
    "        Path to the .npy file containing the dictionary or array\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict or array\n",
    "        Dictionary or array loaded from the .npy file\n",
    "    \"\"\"\n",
    "    loaded_dict = np.load(path, allow_pickle=True)\n",
    "    if isinstance(loaded_dict, np.ndarray):\n",
    "        if loaded_dict.size == 1:\n",
    "            return loaded_dict.item()\n",
    "        return loaded_dict\n",
    "\n",
    "def extract_rgb(image_path, bands=(69, 46, 26)):\n",
    "    \"\"\"extract normalized RGB composite from hyperspectral data \n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to hyperspectral data cube in flat format(h*w, n_bands)\n",
    "        bands: Tuple of band indices to use for R,G,B channels (default: 69,46,26)\n",
    "\n",
    "    Returns:\n",
    "        rgb_normalized: Normalized RGB composite image\n",
    "    \"\"\"\n",
    "    # Load and reshape flat data into cube format\n",
    "    data = np.load(image_path)\n",
    "    rgb_cube = data.reshape(-1, HYPSO_HEIGHT, data.shape[-1])\n",
    "    \n",
    "    # Extract RGB bands and stack them\n",
    "    rgb = np.stack([rgb_cube[..., b] for b in bands], axis=-1)\n",
    "    \n",
    "    # Normalize RGB values to [0,1] range\n",
    "    rgb_normalized = (rgb - np.min(rgb)) / (np.max(rgb) - np.min(rgb))\n",
    "    # Rotate and flip for proper orientation\n",
    "    rgb_normalized = np.rot90(rgb_normalized)\n",
    "    rgb_normalized = np.flipud(rgb_normalized)\n",
    "\n",
    "    return rgb_normalized\n",
    "    \n",
    "def plot_rgb(image_path, bands=(69, 46, 26), figsize=(15, 10)):\n",
    "    \"\"\"Plot RGB composite from hyperspectral data.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to hyperspectral data\n",
    "        bands: RGB band indices (default: 69,46,26)\n",
    "        figsize: Figure size(default: 15x10)\n",
    "    \"\"\"\n",
    "    rgb_normalized = extract_rgb(image_path, bands)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(rgb_normalized, aspect=0.1)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_HUH_label(labels_filepath, key=None, figsize=(15, 10), cmap='viridis'):\n",
    "    \n",
    "    labels = load_path(labels_filepath)\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    if key == None:\n",
    "        # Get max level nodes\n",
    "        max_level = max(len(k) for k in labels.keys())\n",
    "        max_level_keys = [k for k in labels.keys() if len(k) == max_level]\n",
    "        max_level_keys.sort(key=lambda x: int(x, 2))\n",
    "        \n",
    "        combined_label = np.zeros((HYPSO_WIDTH, HYPSO_HEIGHT), dtype=int)\n",
    "        for i, k in enumerate(max_level_keys):\n",
    "            try:\n",
    "                pred_reshaped = labels[k].reshape(HYPSO_WIDTH, HYPSO_HEIGHT)\n",
    "                combined_label[pred_reshaped == True] = i + 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error reshaping key '{k}': {e}\")\n",
    "                continue\n",
    "        plt.imshow(np.flipud(np.rot90(combined_label)), cmap=cmap, vmin=0, aspect=0.1)\n",
    "    else:\n",
    "        if key not in labels:\n",
    "            print(f\"Key '{key}' not found in labelss\")\n",
    "            return\n",
    "        pred_data = labels[key].reshape(HYPSO_WIDTH, HYPSO_HEIGHT)\n",
    "        plt.imshow(np.flipud(np.rot90(pred_data)), cmap=cmap, vmin=0, vmax=1, aspect=0.1)\n",
    "    \n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_HUH_labels_for_level(labels_filepath, level=None, cmap=None, figsize=(15,10)):\n",
    "    \"\"\"\n",
    "    Visualizes binary labels for hierarchical nodes at a specified level.\n",
    "    Highlights overlapping regions between different node labels.\n",
    "    \n",
    "    Args:\n",
    "        labels_filepath (str): Full path to the .npy file containing binary labels\n",
    "        level (int, optional): Hierarchical level to plot. If None, uses maximum level.\n",
    "    \"\"\"\n",
    "    # Load and prepare data\n",
    "    labels = load_path(labels_filepath)\n",
    "    max_level = max(len(k) for k in labels.keys())\n",
    "    level = max_level if level is None or level > max_level else level\n",
    "    \n",
    "    # Get nodes at specified level\n",
    "    level_keys = [k for k in labels.keys() if len(k) == level]\n",
    "    if not level_keys:\n",
    "        print(f\"No nodes found at level {level}\")\n",
    "        return\n",
    "\n",
    "    # Setup visualization\n",
    "    plt.figure(figsize=figsize)\n",
    "    combined_label = np.zeros((HYPSO_WIDTH, HYPSO_HEIGHT), dtype=int)\n",
    "    \n",
    "    # Map each node to a unique label value\n",
    "    for i, k in enumerate(level_keys):\n",
    "        try:\n",
    "            pred_reshaped = labels[k].reshape(HYPSO_WIDTH, HYPSO_HEIGHT)\n",
    "            combined_label[pred_reshaped == True] = i + 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error reshaping key '{k}': {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Create a colormap scaled to the number of nodes\n",
    "    num_nodes = len(level_keys)\n",
    "\n",
    "    if cmap is None:\n",
    "        scaled_cmap = create_discrete_colormap(num_nodes-1) \n",
    "    else:\n",
    "        scaled_cmap = cmap\n",
    "    \n",
    "    # Plot the combined labels\n",
    "    plt.imshow(np.flipud(np.rot90(combined_label)), cmap=scaled_cmap, vmin=0, aspect=0.1)\n",
    "    \n",
    "    # Configure plot\n",
    "    plt.title(f'Binary Labels for Level {level} Nodes')\n",
    "    legend_elements = [plt.Rectangle((0,0),1,1, facecolor=scaled_cmap((i+1)/num_nodes)) for i in range(num_nodes)]\n",
    "    legend_labels = list(level_keys)\n",
    "    plt.legend(legend_elements, legend_labels, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_HUH_unbinarized(deh_obj, node=None, cmap=None, figsize=(15,10)):\n",
    "   \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    ax.imshow(np.flipud(np.rot90(deh_obj.nodes[node].map.reshape(deh_obj.plot_size))),aspect=0.1,  cmap=cmap)\n",
    "    # ax.imshow(np.rot90(deh_obj.nodes[node].map.reshape(deh_obj.plot_size)), aspect=0.1, cmap=cmap)\n",
    "    # ax.set_ylabel(deh_obj.nodes[node_key].map.astype(np.float32).sum())\n",
    "    ax.set_title(node)\n",
    "    fig.savefig(f'node_{node}.png', bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "def plot_all_HUH_unbinarized(image_filepath, cmap=None, figsize=(15,10)):\n",
    "    deh_obj = deh.DEH(no_negative_residuals=True)\n",
    "    deh_obj.load(hUH_model_path)\n",
    "    deh_obj.plot_size=(HYPSO_WIDTH,HYPSO_HEIGHT)\n",
    "    image=load_path(image_filepath)\n",
    "    pred=deh_obj.simple_predict(image)\n",
    "    node_keys = sorted(deh_obj.nodes.keys())\n",
    "    for node_key in node_keys:\n",
    "        # print(f\"Plotting node: {node_key}\")\n",
    "        plot_HUH_unbinarized(deh_obj, node_key, cmap=cmap, figsize=figsize)\n",
    "\n",
    "def plot_spectra_for_level(save_file_path, image_path, level_input=None):\n",
    "    \"\"\"\n",
    "    Plot spectral signatures for nodes at a specified level from a DEH model.\n",
    "    (Using modified deh.py for altered DEH_temp.display_spectra(level_nodes))\n",
    "    Args:\n",
    "        save_file_path: Path to saved DEH model\n",
    "        image_path: Path to flattened input data cube\n",
    "        level_input: Hierarchical level to display (defaults to deepest level)\n",
    "    \"\"\"\n",
    "    DEH_temp = deh.DEH(no_negative_residuals=True)\n",
    "    DEH_temp.load(save_file_path)\n",
    "    cm_input = np.load(image_path)\n",
    "    cube_image = cm_input.reshape(-1,HYPSO_HEIGHT,cm_input.shape[-1])\n",
    "\n",
    "    DEH_temp.plot_size = (cube_image.shape[0],cube_image.shape[1])\n",
    "    DEH_temp.simple_predict(cm_input)\n",
    "    nodes = DEH_temp.nodes\n",
    "    num_levels = max(len(node) for node in DEH_temp.nodes)\n",
    "    \n",
    "    # If level_input is empty or invalid, use the last level\n",
    "    if level_input == None or not isinstance(level_input, int) or level_input > num_levels or level_input < 1:\n",
    "        level = num_levels\n",
    "    else:\n",
    "        level = level_input\n",
    "        \n",
    "    # Get nodes at specified level\n",
    "    level_nodes = [node for node in nodes if len(node) == level]\n",
    "    print(\"using level\", level, \"with\", len(level_nodes), \"nodes\")\n",
    "    DEH_temp.display_spectra(level_nodes, wl=wavelengths)\n",
    "\n",
    "def plot_spectra_for_nodes(save_file_path, image_path, node_keys, ):\n",
    "    \"\"\"\n",
    "    Plot spectral signatures for specified nodes from a DEH model.\n",
    "    (Using modified deh.py for altered DEH_temp.display_spectra(node_keys))\n",
    "    Args:\n",
    "        save_file_path: Path to saved DEH model\n",
    "        image_path: Path to flattened input data cube\n",
    "        node_keys: List of node keys to display spectra for\n",
    "    \"\"\"\n",
    "    DEH_temp = deh.DEH(no_negative_residuals=True)\n",
    "    DEH_temp.load(save_file_path)\n",
    "    cm_input = np.load(image_path)\n",
    "    cube_image = cm_input.reshape(-1,HYPSO_HEIGHT,cm_input.shape[-1])\n",
    "\n",
    "    DEH_temp.plot_size = (cube_image.shape[0],cube_image.shape[1])\n",
    "    DEH_temp.simple_predict(cm_input)\n",
    "    \n",
    "    print(f\"Plotting spectra for {len(node_keys)} nodes\")\n",
    "    DEH_temp.display_spectra(node_keys, wl=wavelengths)\n",
    "\n",
    "def plot_overlay(rgb_image_path, label_path, node_key, alpha=0.5, figsize=(15, 10), rgb_bands=(69, 46, 26)):\n",
    "    \"\"\"\n",
    "    Create an overlay visualization of a hierarchical label node on an RGB image.\n",
    "    \n",
    "    This function generates two side-by-side plots:\n",
    "    1. The original RGB image with the specified node highlighted in red\n",
    "    2. The original RGB image with the inverse of the node highlighted in red\n",
    "    \n",
    "    The overlay uses semi-transparent red coloring (controlled by alpha parameter)\n",
    "    to show where the node occurs in the image.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rgb_image_path : str\n",
    "        Path to the RGB image file (.npy)\n",
    "    label_path : str\n",
    "        Path to the hierarchical label file (.npy)\n",
    "    node_key : str\n",
    "        Key identifying the specific node to visualize\n",
    "    alpha : float, default=0.5\n",
    "        Transparency level of the overlay (0-1)\n",
    "    figsize : tuple, default=(15, 10)\n",
    "        Figure size in inches (width, height)\n",
    "    rgb_bands : tuple, default=(69, 46, 26)\n",
    "        Indices of bands to use for RGB visualization\n",
    "    \"\"\"\n",
    "    # Load and prepare RGB image\n",
    "    rgb_normalized = extract_rgb(rgb_image_path, rgb_bands)\n",
    "    \n",
    "    # Load label data\n",
    "    labels = load_path(label_path)\n",
    "    \n",
    "    if node_key not in labels:\n",
    "        return\n",
    "    \n",
    "    # Get raw mask and reshape to match image dimensions\n",
    "    raw_mask = labels[node_key].astype(int)\n",
    "    \n",
    "    # Reshape to match the dimensions expected by HYPSO\n",
    "    mask_reshaped = raw_mask.reshape(HYPSO_WIDTH, HYPSO_HEIGHT)\n",
    "    \n",
    "    # Rotate and flip to match the RGB image orientation\n",
    "    mask_display = np.rot90(mask_reshaped)\n",
    "    mask_display = np.flipud(mask_display)\n",
    "    \n",
    "    # Create inverse mask directly \n",
    "    inverse_mask = np.ones_like(mask_display) - mask_display\n",
    "    \n",
    "    # Create figure\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
    "    \n",
    "    # Create overlay masks\n",
    "    red_mask = np.zeros(mask_display.shape + (4,))  # RGBA\n",
    "    red_mask[mask_display > 0.5] = [1, 0, 0, alpha]  # Red with alpha\n",
    "    \n",
    "    inverse_red_mask = np.zeros(inverse_mask.shape + (4,))  # RGBA\n",
    "    inverse_red_mask[inverse_mask > 0.5] = [1, 0, 0, alpha]  # Red with alpha\n",
    "    \n",
    "    # Plot directly without using colormap\n",
    "    ax1.imshow(rgb_normalized, aspect=0.1)\n",
    "    ax1.imshow(red_mask, aspect=0.1)\n",
    "    ax1.set_title(f'Node {node_key} Overlay')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    ax2.imshow(rgb_normalized, aspect=0.1)\n",
    "    ax2.imshow(inverse_red_mask, aspect=0.1)\n",
    "    ax2.set_title(f'Inverse Node {node_key} Overlay')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_HUH_overlay_for_level(image_path, HUH_label_path, level=None, alpha=0.5, figsize=(15, 10), rgb_bands=(69, 46, 26)):\n",
    "    \"\"\"\n",
    "    Plot overlay for all nodes in a specific level by calling Plot_HUH_overlay for each node.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image_path : str\n",
    "        Path to the RGB image file\n",
    "    HUH_label_path : str\n",
    "        Path to the label file\n",
    "    level : int, optional\n",
    "        Level number to plot nodes from. If None or invalid, uses the maximum level (default: None)\n",
    "    alpha : float, optional\n",
    "        Transparency of the overlay (default: 0.5)\n",
    "    figsize : tuple, optional\n",
    "        Size of the figure (width, height) in inches (default: (10, 10))\n",
    "    rgb_bands : tuple, optional\n",
    "        RGB band indices to use (default: (69, 46, 26))\n",
    "    \"\"\"\n",
    "    # Load the label data\n",
    "    labels = np.load(HUH_label_path, allow_pickle=True).item()\n",
    "    \n",
    "    # Get all possible levels\n",
    "    available_levels = set(len(key) for key in labels.keys())\n",
    "    \n",
    "    # If level is None or not in available levels, use maximum level\n",
    "    if level is None or level not in available_levels:\n",
    "        level = max(available_levels)\n",
    "        print(f\"Using maximum level: {level}\")\n",
    "    \n",
    "    # Get all nodes for the specified level\n",
    "    level_nodes = [key for key in labels.keys() if len(key) == level]\n",
    "    \n",
    "    if not level_nodes:\n",
    "        print(f\"No nodes found for level {level}\")\n",
    "        return\n",
    "    \n",
    "    # Plot each node using Plot_HUH_overlay\n",
    "    for node_key in level_nodes:\n",
    "        plot_overlay(image_path, HUH_label_path, node_key, alpha, figsize, rgb_bands)\n",
    "\n",
    "def plot_prediction(prediction_path, key=None, figsize=(15, 10), cmap='viridis'):\n",
    "    \"\"\"\n",
    "    Plot prediction results from a prediction file.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    prediction_path : str\n",
    "        Path to the prediction file to load and plot\n",
    "    key : str, optional\n",
    "        Specific key to plot from the prediction dictionary. If empty string (default),\n",
    "        combines all predictions into a single plot\n",
    "    figsize : tuple, optional\n",
    "        Figure size in inches (width, height), default is (15, 10)\n",
    "    cmap : str, optional\n",
    "        Colormap to use for visualization, default is 'viridis'\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "        Displays the plot using matplotlib\n",
    "    \"\"\"\n",
    "    \n",
    "    prediction = load_path(prediction_path)\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    if key == None:\n",
    "        combined_pred = np.zeros((HYPSO_WIDTH, HYPSO_HEIGHT), dtype=int)\n",
    "        for i, k in enumerate(prediction.keys()):\n",
    "            if k == '':\n",
    "                continue\n",
    "            try:\n",
    "                pred_reshaped = prediction[k].reshape(HYPSO_WIDTH, HYPSO_HEIGHT)\n",
    "                combined_pred[pred_reshaped == True] = i + 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error reshaping key '{k}': {e}\")\n",
    "                continue\n",
    "        plt.imshow(np.flipud(np.rot90(combined_pred)), cmap=cmap, vmin=0, vmax=15, aspect=0.1)\n",
    "    else:\n",
    "        if key not in prediction:\n",
    "            print(f\"Key '{key}' not found in predictions\")\n",
    "            return\n",
    "        pred_data = prediction[key].reshape(HYPSO_WIDTH, HYPSO_HEIGHT)\n",
    "        plt.imshow(np.flipud(np.rot90(pred_data)), cmap=cmap, vmin=0, vmax=1, aspect=0.1)\n",
    "    \n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_decoded_prediction(decoded_pred_path, figsize=(15, 10), cmap='viridis'):\n",
    "    \"\"\"\n",
    "    Plot decoded prediction with consistent color mapping.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    decoded_pred_path : str\n",
    "        Path to the decoded prediction file\n",
    "    figsize : tuple\n",
    "        Figure size (width, height)\n",
    "    cmap : str or matplotlib.colors.Colormap\n",
    "        Colormap to use\n",
    "    add_one : bool\n",
    "        Whether to add 1 to all class values\n",
    "    \"\"\"\n",
    "    image = np.load(decoded_pred_path)\n",
    "    image = np.flipud(np.rot90(image))\n",
    "    \n",
    "    # Add 1 to all class values to retain the background value(0) for no class\n",
    "    image = image + 1\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Use proper normalization for discrete colormaps\n",
    "    if isinstance(cmap, plt.matplotlib.colors.ListedColormap):\n",
    "        # For discrete colormaps, we need to be explicit about boundaries\n",
    "        plt.imshow(image, aspect=0.1, cmap=cmap, vmin=0)\n",
    "    else:\n",
    "        # For continuous colormaps like 'viridis'\n",
    "        plt.imshow(image, aspect=0.1, cmap=cmap)\n",
    "        \n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_decoded_overlay(rgb_image_path, label_path, node_key, alpha=0.5, figsize=(15, 10), rgb_bands=(69, 46, 26)):\n",
    "    \"\"\"\n",
    "    Create an overlay visualization of a hierarchical label node on an RGB image.\n",
    "    \n",
    "    This function generates two side-by-side plots:\n",
    "    1. The original RGB image with the specified node highlighted in red\n",
    "    2. The original RGB image with the inverse of the node highlighted in red\n",
    "    \n",
    "    The overlay uses semi-transparent red coloring (controlled by alpha parameter)\n",
    "    to show where the node occurs in the image.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rgb_image_path : str\n",
    "        Path to the RGB image file (.npy)\n",
    "    label_path : str\n",
    "        Path to the hierarchical label file (.npy)\n",
    "    node_key : str\n",
    "        Key identifying the specific node to visualize\n",
    "    alpha : float, default=0.5\n",
    "        Transparency level of the overlay (0-1)\n",
    "    figsize : tuple, default=(15, 10)\n",
    "        Figure size in inches (width, height)\n",
    "    rgb_bands : tuple, default=(69, 46, 26)\n",
    "        Indices of bands to use for RGB visualization\n",
    "    \"\"\"\n",
    "    # Load and prepare RGB image\n",
    "    rgb_normalized = extract_rgb(rgb_image_path, rgb_bands)\n",
    "    \n",
    "    # Load label data\n",
    "    labels = load_path(label_path)\n",
    "    \n",
    "    # Create binary mask where values match node_key\n",
    "    raw_mask = np.zeros_like(labels, dtype=int)\n",
    "    raw_mask[labels == node_key] = 1\n",
    "\n",
    "    # Reshape to match the dimensions expected by HYPSO\n",
    "    mask_reshaped = raw_mask.reshape(HYPSO_WIDTH, HYPSO_HEIGHT)\n",
    "    \n",
    "    # Rotate and flip to match the RGB image orientation\n",
    "    mask_display = np.rot90(mask_reshaped)\n",
    "    mask_display = np.flipud(mask_display)\n",
    "    \n",
    "    # Create inverse mask directly \n",
    "    inverse_mask = np.ones_like(mask_display) - mask_display\n",
    "    \n",
    "    # Create figure\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
    "    \n",
    "    # Create overlay masks\n",
    "    red_mask = np.zeros(mask_display.shape + (4,))  # RGBA\n",
    "    red_mask[mask_display > 0.5] = [1, 0, 0, alpha]  # Red with alpha\n",
    "    \n",
    "    inverse_red_mask = np.zeros(inverse_mask.shape + (4,))  # RGBA\n",
    "    inverse_red_mask[inverse_mask > 0.5] = [1, 0, 0, alpha]  # Red with alpha\n",
    "    \n",
    "    # Plot directly without using colormap\n",
    "    ax1.imshow(rgb_normalized, aspect=0.1)\n",
    "    ax1.imshow(red_mask, aspect=0.1)\n",
    "    ax1.set_title(f'Node {node_key} Overlay')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    ax2.imshow(rgb_normalized, aspect=0.1)\n",
    "    ax2.imshow(inverse_red_mask, aspect=0.1)\n",
    "    ax2.set_title(f'Inverse Node {node_key} Overlay')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_overlay_comparison(rgb_image_path, label_path1, label_path2, node_key, alpha=0.5, figsize=(15, 10), rgb_bands=(69, 46, 26), invert=False):\n",
    "    \"\"\"\n",
    "    Create an overlay visualization comparing two hierarchical label nodes on an RGB image.\n",
    "    \n",
    "    This function generates two side-by-side plots:\n",
    "    1. The original RGB image with the specified node from first label highlighted in red\n",
    "    2. The original RGB image with the specified node from second label highlighted in red\n",
    "    \n",
    "    The overlay uses semi-transparent red coloring (controlled by alpha parameter)\n",
    "    to show where the nodes occur in the image. The RGB image is normalized and displayed\n",
    "    with the specified band indices for visualization.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rgb_image_path : str\n",
    "        Path to the RGB image file (.npy)\n",
    "    label_path1 : str\n",
    "        Path to the first hierarchical label file (.npy)\n",
    "    label_path2 : str\n",
    "        Path to the second hierarchical label file (.npy)\n",
    "    node_key : str\n",
    "        Key identifying the specific node to visualize\n",
    "    alpha : float, default=0.5\n",
    "        Transparency level of the overlay (0-1)\n",
    "    figsize : tuple, default=(15, 10)\n",
    "        Figure size in inches (width, height)\n",
    "    rgb_bands : tuple, default=(69, 46, 26)\n",
    "        Indices of bands to use for RGB visualization (R,G,B)\n",
    "    invert : bool, default=False\n",
    "        Whether to invert the masks before displaying\n",
    "    \"\"\"\n",
    "    # Load and prepare RGB image\n",
    "    rgb_normalized = extract_rgb(rgb_image_path, rgb_bands)\n",
    "    \n",
    "    # Load label data\n",
    "    labels1 = load_path(label_path1)\n",
    "    labels2 = load_path(label_path2)\n",
    "    \n",
    "    if node_key not in labels1 or node_key not in labels2:\n",
    "        return\n",
    "    \n",
    "    # Get raw masks and reshape to match image dimensions\n",
    "    raw_mask1 = labels1[node_key].astype(int)\n",
    "    raw_mask2 = labels2[node_key].astype(int)\n",
    "    \n",
    "    # Reshape to match the dimensions expected by HYPSO\n",
    "    mask_reshaped1 = raw_mask1.reshape(HYPSO_WIDTH, HYPSO_HEIGHT)\n",
    "    mask_reshaped2 = raw_mask2.reshape(HYPSO_WIDTH, HYPSO_HEIGHT)\n",
    "    \n",
    "    # Rotate and flip to match the RGB image orientation\n",
    "    mask_display1 = np.rot90(mask_reshaped1)\n",
    "    mask_display1 = np.flipud(mask_display1)\n",
    "    \n",
    "    mask_display2 = np.rot90(mask_reshaped2)\n",
    "    mask_display2 = np.flipud(mask_display2)\n",
    "    \n",
    "    # Invert masks if requested\n",
    "    if invert:\n",
    "        mask_display1 = 1 - mask_display1\n",
    "        mask_display2 = 1 - mask_display2\n",
    "    \n",
    "    # Create figure\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
    "    \n",
    "    # Create overlay masks\n",
    "    red_mask1 = np.zeros(mask_display1.shape + (4,))  # RGBA\n",
    "    red_mask1[mask_display1 > 0.5] = [1, 0, 0, alpha]  # Red with alpha\n",
    "    \n",
    "    red_mask2 = np.zeros(mask_display2.shape + (4,))  # RGBA\n",
    "    red_mask2[mask_display2 > 0.5] = [1, 0, 0, alpha]  # Red with alpha\n",
    "    \n",
    "    # Plot directly without using colormap\n",
    "    ax1.imshow(rgb_normalized, aspect=0.1)\n",
    "    ax1.imshow(red_mask1, aspect=0.1)\n",
    "    if invert:\n",
    "        ax1.set_title(f'Node {node_key} Overlay (Prediction 1) Inverted')\n",
    "    else:\n",
    "        ax1.set_title(f'Node {node_key} Overlay (Prediction 1)')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    ax2.imshow(rgb_normalized, aspect=0.1)\n",
    "    ax2.imshow(red_mask2, aspect=0.1)\n",
    "    if invert:\n",
    "        ax2.set_title(f'Node {node_key} Overlay (Prediction 2) Inverted')\n",
    "    else:\n",
    "        ax2.set_title(f'Node {node_key} Overlay (Prediction 2)')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_overlay_comparison_for_level(image_path, label_path1, label_path2, level=None, alpha=0.5, figsize=(15, 10), rgb_bands=(69, 46, 26), invert=False):\n",
    "    \"\"\"\n",
    "    Plot overlay for all nodes in a specific level by calling Plot_HUH_overlay for each node.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image_path : str\n",
    "        Path to the RGB image file\n",
    "    HUH_label_path : str\n",
    "        Path to the label file\n",
    "    level : int, optional\n",
    "        Level number to plot nodes from. If None or invalid, uses the maximum level (default: None)\n",
    "    alpha : float, optional\n",
    "        Transparency of the overlay (default: 0.5)\n",
    "    figsize : tuple, optional\n",
    "        Size of the figure (width, height) in inches (default: (10, 10))\n",
    "    rgb_bands : tuple, optional\n",
    "        RGB band indices to use (default: (69, 46, 26))\n",
    "    \"\"\"\n",
    "    # Load the label data\n",
    "    labels1 = np.load(label_path1, allow_pickle=True).item()\n",
    "    labels2 = np.load(label_path2, allow_pickle=True).item()\n",
    "    \n",
    "    # Get all possible levels\n",
    "    available_levels1 = set(len(key) for key in labels1.keys())\n",
    "    available_levels2 = set(len(key) for key in labels2.keys())\n",
    "    \n",
    "    # If level is None or not in available levels, use maximum level\n",
    "    if level is None or level not in available_levels1 or level not in available_levels2:\n",
    "        level = max(available_levels1, available_levels2)\n",
    "        print(f\"Using maximum level: {level}\")\n",
    "    \n",
    "    # Get all nodes for the specified level\n",
    "    level_nodes1 = [key for key in labels1.keys() if len(key) == level]\n",
    "    level_nodes2 = [key for key in labels2.keys() if len(key) == level]\n",
    "    common_nodes = list(set(level_nodes1).intersection(set(level_nodes2)))\n",
    "    # Sort common nodes by their binary value\n",
    "    common_nodes.sort(key=lambda x: int(x, 2))\n",
    "    \n",
    "    if not level_nodes1 or not level_nodes2:\n",
    "        print(f\"No nodes found for level {level}\")\n",
    "        return\n",
    "    \n",
    "    # Plot each node using Plot_HUH_overlay\n",
    "    for node_key in common_nodes:\n",
    "            plot_overlay_comparison(image_path, label_path1, label_path2, node_key, alpha, figsize, rgb_bands, invert)\n",
    "\n",
    "def plot_rgb_labels_and_predictions(image_array=None, label_array=None, prediction_array=None, cmap='viridis'):\n",
    "    if image_array is not None:\n",
    "        n_entries = len(image_array)\n",
    "    elif label_array is not None:\n",
    "        n_entries = len(label_array)\n",
    "    elif prediction_array is not None:\n",
    "        n_entries = len(prediction_array)\n",
    "    else:\n",
    "        print(\"plot_rgb_labels_and_predictions: No data provided\")\n",
    "        return\n",
    "    for i in range(n_entries):\n",
    "        if image_array is not None:\n",
    "            image_path=os.path.join(IMAGES_DIR,image_array[i])\n",
    "            plot_rgb(image_path)\n",
    "        if label_array is not None:\n",
    "            label_path=os.path.join(LABELS_DIR,label_array[i])\n",
    "            plot_HUH_label(label_path, cmap=cmap)\n",
    "        if prediction_array is not None:\n",
    "            predicion_path=os.path.join(PRED_DIR,prediction_array[i])\n",
    "            plot_prediction(predicion_path, cmap=cmap)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rgb(raw_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot labels for hUH label file(.npy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_HUH_label(HUH_label_path, cmap=custom_cmap)\n",
    "plot_HUH_label(HUH_label_path, cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_HUH_labels_for_level(HUH_label_path, level=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLOT SVM TREE prediction(.npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction(SVM_pred_path, cmap=custom_cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot decoded binary SVM TREE prediction(.npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decoded_prediction(DECODED_pred_path,cmap=custom_cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decode binary SVM TREE prediction(.bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_binary_file(binary_file, output_dir):\n",
    "    \n",
    "    # Check if file exists, try different extensions if not\n",
    "    file_to_open = binary_file\n",
    "    if not os.path.exists(file_to_open):\n",
    "        # Try with .bin extension\n",
    "        if os.path.exists(binary_file + \".bin\"):\n",
    "            file_to_open = binary_file + \".bin\"\n",
    "            #print(f\"Found file with .bin extension: {file_to_open}\")\n",
    "        # Try with common extensions\n",
    "        elif os.path.exists(binary_file + \".dat\"):\n",
    "            file_to_open = binary_file + \".dat\"\n",
    "            #print(f\"Found file with .dat extension: {file_to_open}\")\n",
    "        else:\n",
    "            # List similar files in the directory\n",
    "            try:\n",
    "                base_dir = os.path.dirname(binary_file)\n",
    "                base_name = os.path.basename(binary_file)\n",
    "                print(f\"Looking for files similar to {base_name} in {base_dir}\")\n",
    "                similar_files = [f for f in os.listdir(base_dir) if base_name in f]\n",
    "                if similar_files:\n",
    "                    print(f\"Found similar files: {similar_files}\")\n",
    "                    # Use the first match\n",
    "                    file_to_open = os.path.join(base_dir, similar_files[0])\n",
    "                    print(f\"Using: {file_to_open}\")\n",
    "                else:\n",
    "                    print(f\"No similar files found in {base_dir}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error listing directory: {str(e)}\")\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    if output_dir and not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        print(f\"Created output directory: {output_dir}\")\n",
    "    \n",
    "    # Read the entire file\n",
    "    try:\n",
    "        with open(file_to_open, 'rb') as f:\n",
    "            data = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find file {file_to_open}\")\n",
    "        print(\"Please check that the file exists and the path is correct.\")\n",
    "        raise\n",
    "    \n",
    "    print(f\"Successfully opened file: {file_to_open}\")\n",
    "    \n",
    "    # First 8 bytes: timestamps\n",
    "    # Next 16+ bytes: class list (terminated by 255s)\n",
    "    \n",
    "    # Extract class list\n",
    "    class_list = []\n",
    "    for i in range(8, len(data)):\n",
    "        if i >= 24:  # Stop reading classes after 16 bytes\n",
    "            break\n",
    "        if data[i] == 255:  # Stop at first 255\n",
    "            break\n",
    "        class_list.append(data[i])\n",
    "    \n",
    "    print(f\"Classes found in header: {class_list}\")\n",
    "    \n",
    "    # Determine bits per pixel based on number of classes\n",
    "    num_classes = len(class_list)\n",
    "    if num_classes <= 2:\n",
    "        bits_per_pixel = 1  # 1 bit per pixel, 8 pixels per byte\n",
    "    elif num_classes <= 4:\n",
    "        bits_per_pixel = 2  # 2 bits per pixel, 4 pixels per byte\n",
    "    elif num_classes <= 16:\n",
    "        bits_per_pixel = 4  # 4 bits per pixel, 2 pixels per byte\n",
    "    else:\n",
    "        bits_per_pixel = 8  # 8 bits per pixel, 1 pixel per byte\n",
    "    \n",
    "    print(f\"Using {bits_per_pixel} bits per pixel for {num_classes} classes\")\n",
    "    \n",
    "    # Skip header (first 24 bytes)\n",
    "    raw_data = np.frombuffer(data[24:], dtype=np.uint8)\n",
    "    \n",
    "    # Create array to hold decoded labels\n",
    "    total_pixels = HYPSO_HEIGHT * HYPSO_WIDTH\n",
    "    decoded_labels = np.zeros(total_pixels, dtype=np.uint8)\n",
    "    \n",
    "    # Decode based on bits per pixel\n",
    "    if bits_per_pixel == 1:\n",
    "        # 8 pixels per byte\n",
    "        for i in range(min(len(raw_data), total_pixels // 8 + 1)):\n",
    "            for bit in range(8):\n",
    "                pixel_idx = i*8 + bit\n",
    "                if pixel_idx < total_pixels:\n",
    "                    class_idx = (raw_data[i] >> bit) & 0x01\n",
    "                    if class_idx < len(class_list):\n",
    "                        decoded_labels[pixel_idx] = class_list[class_idx]\n",
    "    \n",
    "    elif bits_per_pixel == 2:\n",
    "        # 4 pixels per byte\n",
    "        for i in range(min(len(raw_data), total_pixels // 4 + 1)):\n",
    "            for j in range(4):\n",
    "                pixel_idx = i*4 + j\n",
    "                if pixel_idx < total_pixels:\n",
    "                    class_idx = (raw_data[i] >> (j*2)) & 0x03\n",
    "                    if class_idx < len(class_list):\n",
    "                        decoded_labels[pixel_idx] = class_list[class_idx]\n",
    "    \n",
    "    elif bits_per_pixel == 4:\n",
    "        # 2 pixels per byte\n",
    "        for i in range(min(len(raw_data), total_pixels // 2 + 1)):\n",
    "            # First pixel in high 4 bits\n",
    "            if i*2 < total_pixels:\n",
    "                class_idx = (raw_data[i] >> 4) & 0x0F\n",
    "                if class_idx < len(class_list):\n",
    "                    decoded_labels[i*2] = class_list[class_idx]\n",
    "            \n",
    "            # Second pixel in low 4 bits\n",
    "            if i*2 + 1 < total_pixels:\n",
    "                class_idx = raw_data[i] & 0x0F\n",
    "                if class_idx < len(class_list):\n",
    "                    decoded_labels[i*2 + 1] = class_list[class_idx]\n",
    "    \n",
    "    else:  # bits_per_pixel == 8\n",
    "        # 1 pixel per byte\n",
    "        for i in range(min(len(raw_data), total_pixels)):\n",
    "            class_idx = raw_data[i]\n",
    "            if class_idx < len(class_list):\n",
    "                decoded_labels[i] = class_list[class_idx]\n",
    "    \n",
    "    # Reshape to 2D\n",
    "    decoded_image = decoded_labels.reshape(HYPSO_WIDTH,HYPSO_HEIGHT)\n",
    "    \n",
    "    # Get unique classes in the decoded image\n",
    "    unique_classes = np.unique(decoded_image)\n",
    "    print(f\"Classes in decoded image: {unique_classes}\")\n",
    "    \n",
    "    # Save as numpy array\n",
    "    save_path = os.path.join(output_dir, f\"{os.path.basename(binary_file).replace('.bin', '.npy')}\")\n",
    "    np.save(save_path, decoded_image)\n",
    "    print(f\"Saved decoded labels to {save_path}\")\n",
    "    \n",
    "    # Print class distribution\n",
    "    for cls in unique_classes:\n",
    "        count = np.sum(decoded_image == cls)\n",
    "        percentage = 100.0 * count / total_pixels\n",
    "        print(f\"Class {cls}: {count} pixels ({percentage:.2f}%)\")\n",
    "\n",
    "def decode_binary_files_array(binary_files, output_dir):\n",
    "    for binary_file in binary_files:\n",
    "        binary_file_path = os.path.join(BINARY_PRED_DIR, binary_file)\n",
    "        decode_binary_file(binary_file_path, output_dir=output_dir)\n",
    "\n",
    "def plot_decoded_predictions(binary_files, cmap='viridis'):\n",
    "    for binary_file in binary_files:\n",
    "        binary_file = binary_file.replace('.bin', '.npy')\n",
    "        binary_file_path = os.path.join(DECODED_DIR, binary_file)\n",
    "        plot_decoded_prediction(binary_file_path, cmap=cmap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_binary_files_array(binary_predictions, output_dir=DECODED_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decoded_predictions(decoded_predictions, cmap=custom_cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot spectra for hUH model(.h5) and image (.npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectra_for_level(hUH_model_path, image_path, wl=wavelengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_nodes=[\n",
    "    '0010010',\n",
    "    '0010011',\n",
    "    '0010100',\n",
    "    '0010101',\n",
    "    '0010110',\n",
    "    '0011000',\n",
    "    '0100000'\n",
    "]\n",
    "\n",
    "land_nodes=[\n",
    "    '0000000',\n",
    "    '0000001',\n",
    "    '0000010',\n",
    "    '0000100'\n",
    "]\n",
    "\n",
    "mixed_nodes=[\n",
    "    '0000110',\n",
    "    '0001000',\n",
    "    '0001100',\n",
    "    '0010000',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectra_for_nodes(hUH_model_path, image_path, node_keys=water_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectra_for_nodes(hUH_model_path, image_path, node_keys=land_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectra_for_nodes(hUH_model_path, image_path, node_keys=mixed_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectra_for_nodes(hUH_model_path, image_path, node_keys=['1000000'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLOT HUH_label(.npy) overlay on image(.npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_overlay(raw_image_path, HUH_label_path, node_key='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_HUH_overlay_for_level(raw_image_path, HUH_label_path, level=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPARE PREDICTIONS AND GROUND TRUTH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rgb(raw_image_path)\n",
    "plot_HUH_label(HUH_label_path, cmap=custom_cmap)\n",
    "plot_prediction(SVM_pred_path, cmap=custom_cmap)\n",
    "plot_decoded_prediction(DECODED_pred_path,cmap=custom_cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rgb_labels_and_predictions(image_array=L1A_array, label_array=HUH_labels, prediction_array=SVM_predictions, cmap=custom_cmap)\n",
    "plot_rgb_labels_and_predictions(image_array=H2_L1A_files, label_array=H2_HUH_labels, prediction_array=H2_SVM_predictions, cmap=custom_cmap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_overlay(raw_image_path, HUH_label_path, node_key='0000000')\n",
    "plot_overlay(raw_image_path, SVM_pred_path, node_key='0000000')\n",
    "plot_decoded_overlay(raw_image_path, DECODED_pred_path, node_key=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_overlay_comparison(raw_image_path, HUH_label_path, SVM_pred_path, node_key='0000000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_overlay_comparison_for_level(raw_image_path, HUH_label_path, SVM_pred_path, level=7, invert=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\n",
    "        (0, 0, 0.6),     \n",
    "        (0, 0.35, 0),           \n",
    "        (1, 1, 1)        \n",
    "    ]\n",
    "    \n",
    "    # Create discrete colormap\n",
    "cmap= plt.matplotlib.colors.ListedColormap(colors)\n",
    "\n",
    "def compare_label_files(label_3class_path, label_16class_path, cmap='viridis'):\n",
    "    \"\"\"\n",
    "    Compare two label files - one with 3 classes (.label) and one with 16 classes (.npy)\n",
    "    Maps 16 classes to 3 classes before comparison\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    label_3class_path : str\n",
    "        Path to the 3-class label file (.label format)\n",
    "    label_16class_path : str\n",
    "        Path to the 16-class label file (.npy format)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing comparison metrics\n",
    "    \"\"\"\n",
    "    # Load the label files\n",
    "    label_3class = np.fromfile(label_3class_path, dtype=np.uint8)\n",
    "    label_16class = np.load(label_16class_path)\n",
    "    \n",
    "    # Reshape to HYPSO dimensions\n",
    "    label_3class = label_3class.reshape(HYPSO_WIDTH,HYPSO_HEIGHT)\n",
    "    label_3class = np.rot90(label_3class)\n",
    "    label_16class = label_16class.reshape(HYPSO_WIDTH,HYPSO_HEIGHT)\n",
    "    label_16class = np.rot90(label_16class)\n",
    "    \n",
    "\n",
    "    class_mapping = {\n",
    "        0: 1,  \n",
    "        1: 1,  \n",
    "        2: 1,\n",
    "        3: 1,\n",
    "        4: 1,\n",
    "        5: 1,\n",
    "        6: 1,\n",
    "        7: 0,\n",
    "        8: 0,\n",
    "        9: 0,\n",
    "        10: 0,\n",
    "        11: 0,\n",
    "        12: 0,\n",
    "        13: 0,\n",
    "        14: 2,  \n",
    "        15: 2\n",
    "    }\n",
    "    \n",
    "    # Map 16-class labels to 3 classes\n",
    "    mapped_16class = np.zeros_like(label_16class)\n",
    "    for old_class, new_class in class_mapping.items():\n",
    "        mapped_16class[label_16class == old_class] = new_class\n",
    "    \n",
    "    # Calculate accuracy using mapped labels\n",
    "    total_pixels = label_3class.size\n",
    "    correct_pixels = np.sum(label_3class == mapped_16class)\n",
    "    accuracy = correct_pixels / total_pixels\n",
    "    \n",
    "    # Calculate per-class accuracy\n",
    "    unique_classes = np.unique(label_3class)\n",
    "    per_class_acc = {}\n",
    "    for cls in unique_classes:\n",
    "        class_mask = label_3class == cls\n",
    "        if np.any(class_mask):\n",
    "            class_acc = np.sum((label_3class == mapped_16class) & class_mask) / np.sum(class_mask)\n",
    "            per_class_acc[cls] = class_acc\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig1 = plt.figure(figsize=(15, 5))\n",
    "    ax1 = fig1.add_subplot(111)\n",
    "    ax1.imshow(label_3class, cmap=cmap)\n",
    "    ax1.set_title('1D-Justo-LiuNet sea land cloud')\n",
    "    ax1.axis('off')\n",
    "    ax1.set_aspect(0.1)\n",
    "    \n",
    "    fig2 = plt.figure(figsize=(15, 5))\n",
    "    ax2 = fig2.add_subplot(111)\n",
    "    ax2.imshow(mapped_16class, cmap=cmap)\n",
    "    ax2.set_title('SVM BDT 16 classes mapped to sea land cloud')\n",
    "    ax2.axis('off')\n",
    "    ax2.set_aspect(0.1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Overall Accuracy: {accuracy:.3f}\")\n",
    "    print(\"\\nPer-class Accuracy:\")\n",
    "    for cls, acc in per_class_acc.items():\n",
    "        print(f\"Class {cls}: {acc:.3f}\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'per_class_accuracy': per_class_acc,\n",
    "        'mapped_labels': mapped_16class\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_3class = r'data\\decoded_predictions\\tampa_2024-11-12T15-31-55Z_jon-cnn.labels'\n",
    "label_16class= r'data\\decoded_predictions\\tampa_2024-11-12T15-31-55Z_16end.npy'\n",
    "results = compare_label_files(label_3class, label_16class,cmap=cmap)\n",
    "label_3class = r'data\\decoded_predictions\\vancouver_2025-05-04T19-12-24Z_sea-land-cloud.labels'\n",
    "label_16class= r'data\\decoded_predictions\\vancouver_2025-05-04T19-12-24Z_16end.npy'\n",
    "results = compare_label_files(label_3class, label_16class,cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_HUH_unbinarized(image_path, cmap='copper', figsize=(30,30))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hypso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
