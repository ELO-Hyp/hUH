{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib as il\n",
    "from hypso import Hypso1\n",
    "from sklearn.svm import LinearSVC\n",
    "import src.deh as deh\n",
    "import copy\n",
    "il.reload(deh)\n",
    "sys.path.append(os.path.abspath(\"D:/Hierarchical Unmixing Label\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPSO_HEIGHT=598\n",
    "HYPSO_WIDTH=1092\n",
    "HYPSO_BANDS=112"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASS DECISION TREE DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryDecisionTree:\n",
    "    def __init__(self, all_labels, verbose=False):\n",
    "        self.verbose = verbose\n",
    "        self.all_labels = all_labels\n",
    "        self.endmembers = []\n",
    "        self.splitting_nodes = []\n",
    "        self.models = {}  # Dictionary to store SVM models for each splitting node\n",
    "        self.initialize_tree_structure(all_labels.keys())\n",
    "        \n",
    "    def initialize_tree_structure(self, all_keys):\n",
    "        \"\"\"Initialize the tree structure by identifying endmembers and splitting nodes\"\"\"\n",
    "        print(\"Initializing Binary Decision Tree structure...\")\n",
    "        self.identify_set_endmembers(all_keys)\n",
    "        self.identify_set_splitting_nodes(all_keys)\n",
    "        \n",
    "    def identify_set_endmembers(self, all_keys):\n",
    "        max_length = max(len(key) for key in all_keys)\n",
    "        self.endmembers = []\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"IDENTIFYING ENDMEMBERS:\")\n",
    "            print(\"=\"*50)\n",
    "            print(f\"Maximum key length found: {max_length}\")\n",
    "            print(\"-\"*50)\n",
    "        \n",
    "        for key in all_keys:\n",
    "            if len(key) == max_length:\n",
    "                self.endmembers.append(key)\n",
    "                if self.verbose:\n",
    "                    print(f\"Found endmember: '{key}'\")\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"Total endmembers identified: {len(self.endmembers)}\")\n",
    "        \n",
    "    def identify_set_splitting_nodes(self, all_keys):\n",
    "        self.splitting_nodes = []\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"IDENTIFYING SPLITTING NODES:\")\n",
    "            print(\"=\"*50)\n",
    "        \n",
    "        for key in all_keys:\n",
    "            has_zero = key + '0' in all_keys\n",
    "            has_one = key + '1' in all_keys\n",
    "            if has_zero and has_one:\n",
    "                self.splitting_nodes.append(key)\n",
    "                if self.verbose:\n",
    "                    print(f\"Found splitting node: '{key}' â†’ branches to '{key}0' and '{key}1'\")\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"-\"*50)\n",
    "            print(f\"Total splitting nodes identified: {len(self.splitting_nodes)}\")\n",
    "\n",
    "    def _preprocess_input(self, X):\n",
    "        \"\"\"\n",
    "        Preprocess input data to ensure it's in the right format (n_samples, n_bands)\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : numpy.ndarray\n",
    "            Hyperspectral image data. Can be:\n",
    "            - Flattened array of shape (n_samples, n_bands)\n",
    "            - Cube of shape (height, width, n_bands) or (n_bands, height, width)\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        X_processed : numpy.ndarray\n",
    "            Processed data of shape (n_samples, n_bands)\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            print(f\"\\nPreprocessing input data with shape: {X.shape}\")\n",
    "            \n",
    "        # If already 2D with samples as first dimension, return as is\n",
    "        if len(X.shape) == 2:\n",
    "            if self.verbose:\n",
    "                print(f\"Input is already in correct format: {X.shape}\")\n",
    "                print(\"-\"*50)\n",
    "            return X\n",
    "        \n",
    "        # Handle 3D data (cube)\n",
    "        elif len(X.shape) == 3:\n",
    "            # Determine which dimension is the spectral dimension\n",
    "            # Typically, spectral dimension is the smallest\n",
    "            dims = np.array(X.shape)\n",
    "            spectral_dim = np.argmin(dims)\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(f\"Detected spectral dimension: {spectral_dim}\")\n",
    "            \n",
    "            if spectral_dim == 0:  # (n_bands, height, width)\n",
    "                n_bands, height, width = X.shape\n",
    "                if self.verbose:\n",
    "                    print(f\"Reshaping from (n_bands={n_bands}, height={height}, width={width}) to ({height*width}, {n_bands})\")\n",
    "                    print(\"-\"*50)\n",
    "                return X.reshape(n_bands, -1).T  # Reshape to (height*width, n_bands)\n",
    "            \n",
    "            elif spectral_dim == 2:  # (height, width, n_bands)\n",
    "                height, width, n_bands = X.shape\n",
    "                if self.verbose:\n",
    "                    print(f\"Reshaping from (height={height}, width={width}, n_bands={n_bands}) to ({height*width}, {n_bands})\")\n",
    "                    print(\"-\"*50)\n",
    "                return X.reshape(-1, n_bands)  # Reshape to (height*width, n_bands)\n",
    "            \n",
    "            else:  # (height, n_bands, width) - unusual but handle it\n",
    "                height, n_bands, width = X.shape\n",
    "                if self.verbose:\n",
    "                    print(f\"Unusual format detected: (height={height}, n_bands={n_bands}, width={width})\")\n",
    "                    print(f\"Reshaping to ({height*width}, {n_bands})\")\n",
    "                    print(\"-\"*50)\n",
    "                return X.transpose(0, 2, 1).reshape(-1, n_bands)  # Reshape to (height*width, n_bands)\n",
    "        \n",
    "        \n",
    "        else:\n",
    "            if self.verbose:\n",
    "                print(f\"Error: Unsupported input shape: {X.shape}\")\n",
    "            raise ValueError(f\"Unsupported input shape: {X.shape}. Expected 2D or 3D array.\")\n",
    "    \n",
    "    def train(self, X, labels=None):\n",
    "        \"\"\"\n",
    "        Train SVMs for each splitting node\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : numpy.ndarray\n",
    "            Hyperspectral image data. Can be:\n",
    "            - Flattened array of shape (n_samples, n_bands)\n",
    "            - Cube of shape (height, width, n_bands) or (n_bands, height, width)\n",
    "        labels : dict, optional\n",
    "            Labels to use for training. If None, uses the labels provided during initialization.\n",
    "        \"\"\"\n",
    "        from sklearn.svm import LinearSVC\n",
    "        \n",
    "        # Process input data to ensure it's in the right format (n_samples, n_bands)\n",
    "        X = self._preprocess_input(X)\n",
    "        \n",
    "        # Use provided labels or fall back to the ones from initialization\n",
    "        training_labels = labels if labels is not None else self.all_labels\n",
    "        \n",
    "        # if self.verbose:\n",
    "        if True:\n",
    "            print(\"Training SVMs for each splitting node...\")\n",
    "        \n",
    "        for node in self.splitting_nodes:\n",
    "            print(\"Splitting node:\",node)\n",
    "            # Get labels for this node\n",
    "            y_parent = training_labels[node]\n",
    "            \n",
    "            # Only consider pixels that belong to this node\n",
    "            mask = y_parent == 1\n",
    "            X_node = X[mask]\n",
    "            \n",
    "            # Get labels for children nodes\n",
    "            left_child = node + '0'\n",
    "            right_child = node + '1'\n",
    "            \n",
    "            # Create binary labels for SVM (1 for right child, 0 for left child)\n",
    "            y_train = np.zeros(X_node.shape[0], dtype=int)\n",
    "            \n",
    "            # Find indices where right child is 1\n",
    "            if right_child in training_labels:\n",
    "                right_mask = training_labels[right_child][mask] == 1\n",
    "                y_train[right_mask] = 1\n",
    "            \n",
    "            # Train LinearSVC\n",
    "            model = LinearSVC(dual='auto', random_state=42)\n",
    "            model.fit(X_node, y_train)\n",
    "            \n",
    "            # Store the model\n",
    "            self.models[node] = model\n",
    "            \n",
    "            # if self.verbose:\n",
    "            if True:\n",
    "                print(f\"Trained model for node '{node}'\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict endmember classes for input data\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : numpy.ndarray\n",
    "            Hyperspectral image data. Can be:\n",
    "            - Flattened array of shape (n_samples, n_bands)\n",
    "            - Cube of shape (height, width, n_bands) or (n_bands, height, width)\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        predictions : dict\n",
    "            Dictionary with keys for each endmember and values as binary masks\n",
    "        \"\"\"\n",
    "        # Process input data to ensure it's in the right format (n_samples, n_bands)\n",
    "        X = self._preprocess_input(X)\n",
    "        \n",
    "        n_samples = X.shape[0]\n",
    "        \n",
    "        # Initialize predictions with all True for root node\n",
    "        current_predictions = {\n",
    "            '': np.ones(n_samples, dtype=bool)\n",
    "        }\n",
    "        \n",
    "        # Process each level of the tree\n",
    "        for level in range(max(len(node) for node in self.splitting_nodes) + 1):\n",
    "            # Get nodes at this level\n",
    "            level_nodes = [node for node in self.splitting_nodes if len(node) == level]\n",
    "            \n",
    "            for node in level_nodes:\n",
    "                # Skip if no samples belong to this node\n",
    "                if not np.any(current_predictions[node]):\n",
    "                    continue\n",
    "                \n",
    "                # Get samples that belong to this node\n",
    "                node_mask = current_predictions[node]\n",
    "                X_node = X[node_mask]\n",
    "                \n",
    "                # Predict using the SVM model\n",
    "                if len(X_node) > 0:\n",
    "                    y_pred = self.models[node].predict(X_node)\n",
    "                    \n",
    "                    # Create masks for children\n",
    "                    left_child = node + '0'\n",
    "                    right_child = node + '1'\n",
    "                    \n",
    "                    # Initialize child predictions\n",
    "                    if left_child not in current_predictions:\n",
    "                        current_predictions[left_child] = np.zeros(n_samples, dtype=bool)\n",
    "                    if right_child not in current_predictions:\n",
    "                        current_predictions[right_child] = np.zeros(n_samples, dtype=bool)\n",
    "                    \n",
    "                    # Update predictions for children\n",
    "                    left_indices = np.where(node_mask)[0][y_pred == 0]\n",
    "                    right_indices = np.where(node_mask)[0][y_pred == 1]\n",
    "                    \n",
    "                    current_predictions[left_child][left_indices] = True\n",
    "                    current_predictions[right_child][right_indices] = True\n",
    "        \n",
    "        # For non-splitting nodes that just have a single child with '0' appended\n",
    "        for key in self.all_labels.keys():\n",
    "            if key not in self.splitting_nodes and key != '':\n",
    "                # Find the parent node\n",
    "                parent = key[:-1]\n",
    "                if parent in current_predictions and key not in current_predictions:\n",
    "                    # If this is a non-splitting child, it inherits parent's prediction\n",
    "                    current_predictions[key] = current_predictions[parent].copy()\n",
    "        \n",
    "        # Extract predictions for endmembers\n",
    "        endmember_predictions = {}\n",
    "        for endmember in self.endmembers:\n",
    "            if endmember in current_predictions:\n",
    "                endmember_predictions[endmember] = current_predictions[endmember]\n",
    "            else:\n",
    "                # If endmember not in predictions, try to find its parent\n",
    "                parent = endmember[:-1]\n",
    "                while parent and parent not in current_predictions:\n",
    "                    parent = parent[:-1]\n",
    "                if parent:\n",
    "                    endmember_predictions[endmember] = current_predictions[parent].copy()\n",
    "                else:\n",
    "                    endmember_predictions[endmember] = np.zeros(n_samples, dtype=bool)\n",
    "        \n",
    "        return endmember_predictions\n",
    "    \n",
    "    def evaluate(self, X, gt_labels=None):\n",
    "        \"\"\"\n",
    "        Evaluate the model on test data\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : numpy.ndarray\n",
    "            Hyperspectral image data. Can be:\n",
    "            - Flattened array of shape (n_samples, n_bands)\n",
    "            - Cube of shape (height, width, n_bands) or (n_bands, height, width)\n",
    "        gt_labels : dict, optional\n",
    "            Ground truth labels for evaluation. If None, uses self.all_labels\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        accuracy : float\n",
    "            Overall accuracy of endmember predictions\n",
    "        \"\"\"\n",
    "        if gt_labels is None:\n",
    "            gt_labels = self.all_labels\n",
    "            \n",
    "        # if self.verbose:\n",
    "        if True:\n",
    "            print(\"Starting evaluation...\")\n",
    "            \n",
    "        predictions = self.predict(X)\n",
    "        \n",
    "        # Calculate accuracy for endmembers\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"Evaluating accuracy for {len(self.endmembers)} endmembers...\")\n",
    "            \n",
    "        endmember_accuracies = {}\n",
    "        for endmember in self.endmembers:\n",
    "            if endmember in predictions and endmember in gt_labels:\n",
    "                pred = predictions[endmember]\n",
    "                true = gt_labels[endmember]\n",
    "                \n",
    "                endmember_correct = np.sum(pred == true)\n",
    "                endmember_total = len(true)\n",
    "                \n",
    "                correct += endmember_correct\n",
    "                total += endmember_total\n",
    "                \n",
    "                if self.verbose:\n",
    "                    endmember_acc = endmember_correct / endmember_total if endmember_total > 0 else 0\n",
    "                    endmember_accuracies[endmember] = endmember_acc\n",
    "                    print(f\"  Endmember '{endmember}': {endmember_acc:.4f} ({endmember_correct}/{endmember_total})\")\n",
    "        \n",
    "        accuracy = correct / total if total > 0 else 0\n",
    "        \n",
    "        # if self.verbose:\n",
    "        if True:\n",
    "            print(f\"Overall accuracy: {accuracy:.4f} ({correct}/{total} pixels)\")\n",
    "            \n",
    "        return accuracy\n",
    "\n",
    "    def plot_input_image(self, image_data, slice_idx=None, figsize=(15, 5), cmap='viridis', rgb_bands=(69, 46, 26)):\n",
    "        \"\"\"Plot input image data as single band, RGB composite, or flat image.\"\"\"\n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "        # Preprocess input data for more efficient handling\n",
    "        image_data = np.asarray(image_data)  # Ensure numpy array\n",
    "        \n",
    "        # Handle flat images (h*w, n_bands)\n",
    "        if len(image_data.shape) == 2 and image_data.shape[1] > 3:\n",
    "            slice_idx = slice_idx if slice_idx is not None else image_data.shape[1] // 2\n",
    "            band_data = image_data[:, slice_idx]\n",
    "            \n",
    "            # Try to reshape to a square-ish image if possible\n",
    "            side = int(np.sqrt(image_data.shape[0]))\n",
    "            reshaped_data = band_data.reshape(side, side) if side * side == image_data.shape[0] else band_data.reshape(-1, 1)\n",
    "            plt.imshow(np.rot90(reshaped_data), cmap=cmap, aspect=0.1)\n",
    "            plt.colorbar(label='Intensity')\n",
    "            plt.title(f'Input Image - Band {slice_idx} (Flattened)')\n",
    "        \n",
    "        # Handle 3D data (h, w, n_bands)\n",
    "        elif len(image_data.shape) == 3:\n",
    "            h, w, n_bands = image_data.shape\n",
    "            slice_idx = slice_idx if slice_idx is not None else n_bands // 2\n",
    "            \n",
    "            # Create RGB composite if bands are specified\n",
    "            if rgb_bands is not None and len(rgb_bands) == 3:\n",
    "                r_idx, g_idx, b_idx = rgb_bands\n",
    "                if max(rgb_bands) > n_bands - 1:\n",
    "                    raise ValueError(f\"RGB band indices {rgb_bands} exceed available bands (0-{n_bands-1})\")\n",
    "                \n",
    "                # More efficient RGB creation - preallocate and process in one go\n",
    "                rgb_img = np.zeros((h, w, 3), dtype=np.float32)\n",
    "                for i, band_idx in enumerate([r_idx, g_idx, b_idx]):\n",
    "                    band = image_data[:, :, band_idx].astype(np.float32)\n",
    "                    # Normalize only if needed\n",
    "                    band_min, band_max = band.min(), band.max()\n",
    "                    if band_min != band_max:\n",
    "                        band = (band - band_min) / (band_max - band_min)\n",
    "                    rgb_img[:, :, i] = band\n",
    "                \n",
    "                plt.imshow(np.rot90(rgb_img), aspect=0.1)\n",
    "                plt.title(f'RGB Composite (R:{r_idx}, G:{g_idx}, B:{b_idx})')\n",
    "            else:\n",
    "                plt.imshow(np.rot90(image_data[:, :, slice_idx]), cmap=cmap, aspect=0.1)\n",
    "                plt.colorbar(label='Intensity')\n",
    "                plt.title(f'Input Image - Band {slice_idx}')\n",
    "        \n",
    "        # Handle other cases\n",
    "        else:\n",
    "            plt.imshow(np.rot90(image_data), cmap=cmap, aspect=0.1)\n",
    "            plt.colorbar(label='Intensity')\n",
    "            plt.title('Input Image')\n",
    "        \n",
    "        plt.axis('on')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_ground_truth(self, labels=None, key='', figsize=(15, 5), cmap='tab10'):\n",
    "        \"\"\"Plot ground truth labels.\"\"\"\n",
    "        # Preprocess input\n",
    "        labels = self.all_labels if labels is None else labels\n",
    "        \n",
    "        # Handle dictionary-type labels\n",
    "        if isinstance(labels, dict):\n",
    "            if key == '':\n",
    "                # Create a combined view of all endmembers\n",
    "                plt.figure(figsize=figsize)\n",
    "                first_val = list(labels.values())[0]\n",
    "                \n",
    "                if len(first_val.shape) == 1:\n",
    "                    combined_labels = np.zeros((HYPSO_HEIGHT, HYPSO_WIDTH), dtype=int)\n",
    "                    endmember_keys = [k for k in labels.keys() if k in self.endmembers]\n",
    "                    \n",
    "                    # More efficient processing - prepare data before visualization\n",
    "                    for i, k in enumerate(endmember_keys):\n",
    "                        if k == '':\n",
    "                            continue\n",
    "                        try:\n",
    "                            label_reshaped = labels[k].reshape(HYPSO_HEIGHT, HYPSO_WIDTH)\n",
    "                            combined_labels[label_reshaped == 1] = i + 1\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error reshaping key '{k}': {e}\")\n",
    "                            continue\n",
    "                    \n",
    "                    # Rotate the image 90 degrees and set aspect ratio\n",
    "                    plt.imshow(np.rot90(combined_labels), cmap=cmap, aspect=0.1)\n",
    "                    \n",
    "                    # Create legend\n",
    "                    from matplotlib.patches import Patch\n",
    "                    cmap_obj = plt.colormaps.get_cmap(cmap)\n",
    "                    \n",
    "                    keys_to_show = endmember_keys[:20]\n",
    "                    if len(endmember_keys) > 20:\n",
    "                        print(f\"Showing only first 20 of {len(endmember_keys)} keys in legend\")\n",
    "                    \n",
    "                    legend_elements = [Patch(facecolor=cmap_obj((i+1)/(len(keys_to_show)+1)), label=k) \n",
    "                                      for i, k in enumerate(keys_to_show) if k != '']\n",
    "                    \n",
    "                    plt.legend(handles=legend_elements, loc='best', title='Labels', fontsize='small')\n",
    "                    plt.title('Ground Truth Labels - Combined View')\n",
    "                else:\n",
    "                    print(\"Cannot display labels: unexpected format\")\n",
    "            else:\n",
    "                # Plot just the specified key\n",
    "                if key not in labels:\n",
    "                    print(f\"Key '{key}' not found in labels\")\n",
    "                    return\n",
    "                \n",
    "                label_data = labels[key]\n",
    "                if len(label_data.shape) == 1:\n",
    "                    try:\n",
    "                        label_data = label_data.reshape(HYPSO_HEIGHT, HYPSO_WIDTH)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reshaping label data: {e}\")\n",
    "                        return\n",
    "                \n",
    "                plt.figure(figsize=figsize)\n",
    "                # Use viridis colormap for the binary data and rotate the image 90 degrees\n",
    "                im = plt.imshow(np.rot90(label_data), cmap='viridis', vmin=0, vmax=1, aspect=0.1)\n",
    "                plt.title(f'Ground Truth Label for \"{key}\"')\n",
    "                \n",
    "                # Add a simple legend for present/absent\n",
    "                from matplotlib.patches import Patch\n",
    "                cmap_obj = plt.colormaps.get_cmap('viridis')\n",
    "                legend_elements = [\n",
    "                    Patch(facecolor=cmap_obj(0.0), label='Absent (0)'),\n",
    "                    Patch(facecolor=cmap_obj(1.0), label='Present (1)')\n",
    "                ]\n",
    "                plt.legend(handles=legend_elements, loc='best')\n",
    "        \n",
    "        # Handle array-type labels\n",
    "        elif hasattr(labels, 'shape'):\n",
    "            # Preprocess array data\n",
    "            labels = np.asarray(labels)  # Ensure numpy array\n",
    "            if len(labels.shape) == 1:\n",
    "                try:\n",
    "                    labels = labels.reshape(HYPSO_HEIGHT, HYPSO_WIDTH)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reshaping label data: {e}\")\n",
    "                    return\n",
    "            \n",
    "            plt.figure(figsize=figsize)\n",
    "            # Rotate the image 90 degrees and set aspect ratio\n",
    "            im = plt.imshow(np.rot90(labels), cmap=cmap, aspect=0.1)\n",
    "            plt.colorbar(im, label='Label')\n",
    "            plt.title('Ground Truth Labels')\n",
    "        else:\n",
    "            print(\"Cannot plot labels: unsupported format\")\n",
    "            return\n",
    "        \n",
    "        plt.axis('on')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_prediction(self, prediction=None, key='', figsize=(15, 5), cmap='tab10'):\n",
    "        \"\"\"Plot prediction results.\"\"\"\n",
    "        # Preprocess input\n",
    "        if prediction is None:\n",
    "            if not hasattr(self, 'last_prediction'):\n",
    "                print(\"No prediction available. Run predict() first.\")\n",
    "                return\n",
    "            prediction = self.last_prediction\n",
    "        \n",
    "        # Handle dictionary-type predictions\n",
    "        if isinstance(prediction, dict):\n",
    "            if key == '':\n",
    "                plt.figure(figsize=figsize)\n",
    "                first_val = list(prediction.values())[0]\n",
    "                \n",
    "                if len(first_val.shape) == 1:\n",
    "                    combined_pred = np.zeros((HYPSO_HEIGHT, HYPSO_WIDTH), dtype=int)\n",
    "                    endmember_keys = [k for k in prediction.keys() if k in self.endmembers]\n",
    "                    \n",
    "                    # More efficient processing - prepare data before visualization\n",
    "                    for i, k in enumerate(endmember_keys):\n",
    "                        if k == '':\n",
    "                            continue\n",
    "                        try:\n",
    "                            pred_reshaped = prediction[k].reshape(HYPSO_HEIGHT, HYPSO_WIDTH)\n",
    "                            combined_pred[pred_reshaped == True] = i + 1\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error reshaping key '{k}': {e}\")\n",
    "                            continue\n",
    "                    \n",
    "                    # Rotate the image 90 degrees and set aspect ratio\n",
    "                    plt.imshow(np.rot90(combined_pred), cmap=cmap, aspect=0.1)\n",
    "                    \n",
    "                    # Create legend\n",
    "                    from matplotlib.patches import Patch\n",
    "                    cmap_obj = plt.colormaps.get_cmap(cmap)\n",
    "                    \n",
    "                    keys_to_show = endmember_keys[:20]\n",
    "                    if len(endmember_keys) > 20:\n",
    "                        print(f\"Showing only first 20 of {len(endmember_keys)} keys in legend\")\n",
    "                    \n",
    "                    legend_elements = [Patch(facecolor=cmap_obj((i+1)/(len(keys_to_show)+1)), label=k) \n",
    "                                      for i, k in enumerate(keys_to_show) if k != '']\n",
    "                    \n",
    "                    plt.legend(handles=legend_elements, loc='best', title='Predictions', fontsize='small')\n",
    "                    plt.title('Predictions - Combined View')\n",
    "                else:\n",
    "                    print(\"Cannot display predictions: unexpected format\")\n",
    "            else:\n",
    "                if key not in prediction:\n",
    "                    print(f\"Key '{key}' not found in predictions\")\n",
    "                    return\n",
    "                \n",
    "                pred_data = prediction[key]\n",
    "                if len(pred_data.shape) == 1:\n",
    "                    try:\n",
    "                        pred_data = pred_data.reshape(HYPSO_HEIGHT, HYPSO_WIDTH)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reshaping prediction data: {e}\")\n",
    "                        return\n",
    "                \n",
    "                plt.figure(figsize=figsize)\n",
    "                # Use viridis colormap for the binary data, rotate 90 degrees and set aspect ratio\n",
    "                im = plt.imshow(np.rot90(pred_data), cmap='viridis', vmin=0, vmax=1, aspect=0.1)\n",
    "                plt.title(f'Prediction for key \"{key}\"')\n",
    "                \n",
    "                # Add a simple legend for present/absent\n",
    "                from matplotlib.patches import Patch\n",
    "                cmap_obj = plt.colormaps.get_cmap('viridis')\n",
    "                legend_elements = [\n",
    "                    Patch(facecolor=cmap_obj(0.0), label='Absent (0)'),\n",
    "                    Patch(facecolor=cmap_obj(1.0), label='Present (1)')\n",
    "                ]\n",
    "                plt.legend(handles=legend_elements, loc='best')\n",
    "        \n",
    "        # Handle array-type predictions\n",
    "        elif hasattr(prediction, 'shape'):\n",
    "            # Preprocess array data\n",
    "            prediction = np.asarray(prediction)  # Ensure numpy array\n",
    "            if len(prediction.shape) == 1:\n",
    "                try:\n",
    "                    prediction = prediction.reshape(HYPSO_HEIGHT, HYPSO_WIDTH)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reshaping prediction data: {e}\")\n",
    "                    return\n",
    "            \n",
    "            plt.figure(figsize=figsize)\n",
    "            # Rotate the image 90 degrees and set aspect ratio\n",
    "            im = plt.imshow(np.rot90(prediction), cmap=cmap, aspect=0.1)\n",
    "            plt.colorbar(im, label='Prediction')\n",
    "            plt.title('Prediction')\n",
    "        else:\n",
    "            print(\"Cannot plot prediction: unsupported format\")\n",
    "            return\n",
    "        \n",
    "        plt.axis('on')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def save_model_parameters(self, filename='decision_tree_model.pkl'):\n",
    "        \"\"\"\n",
    "        Save the trained SVM parameters of the decision tree to a file.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        filename : str\n",
    "            The name of the file to save the model parameters to.\n",
    "        \"\"\"\n",
    "        import pickle\n",
    "        import os\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"Preparing to save model parameters...\")\n",
    "            for node, model in self.models.items():\n",
    "                if hasattr(model, 'coef_'):\n",
    "                    print(f\"Node {node} SVM weights shape: {model.coef_.shape}\")\n",
    "                    print(f\"Node {node} SVM weights: {model.coef_}\")\n",
    "                if hasattr(model, 'intercept_'):\n",
    "                    print(f\"Node {node} SVM intercept: {model.intercept_}\")\n",
    "        \n",
    "        # Create a dictionary to store all model data\n",
    "        model_data = {\n",
    "            'models': self.models,  # This is your dictionary of SVM models\n",
    "            'endmembers': self.endmembers,\n",
    "            'splitting_nodes': self.splitting_nodes,\n",
    "            'all_labels': self.all_labels  # Save the labels too\n",
    "        }\n",
    "        \n",
    "        # Ensure weights folder exists\n",
    "        weights_folder = 'weights'\n",
    "        os.makedirs(weights_folder, exist_ok=True)\n",
    "        \n",
    "        # Create full path to save file in weights folder\n",
    "        filepath = os.path.join(weights_folder, filename)\n",
    "        \n",
    "        try:\n",
    "            if self.verbose:\n",
    "                print(f\"Saving model to {filepath}...\")\n",
    "            with open(filepath, 'wb') as f:\n",
    "                pickle.dump(model_data, f)\n",
    "            print(f\"Model parameters successfully saved to {filepath}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving model parameters: {e}\")\n",
    "\n",
    "    def load_model_parameters(self, filename='decision_tree_model.pkl'):\n",
    "        \"\"\"\n",
    "        Load the trained SVM parameters for the decision tree from a file.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        filename : str\n",
    "            The name of the file to load the model parameters from.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        bool\n",
    "            True if loading was successful, False otherwise.\n",
    "        \"\"\"\n",
    "        import pickle\n",
    "        import os\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"Attempting to load model parameters from {filename}...\")\n",
    "        \n",
    "        # Create full path to load file from weights folder\n",
    "        filepath = os.path.join('weights', filename)\n",
    "        \n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"Error: Model file {filepath} not found\")\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            if self.verbose:\n",
    "                print(\"Reading model file...\")\n",
    "            with open(filepath, 'rb') as f:\n",
    "                model_data = pickle.load(f)\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(\"Restoring model components...\")\n",
    "            \n",
    "            # Restore the model components\n",
    "            self.models = model_data['models']\n",
    "            self.endmembers = model_data['endmembers']\n",
    "            self.splitting_nodes = model_data['splitting_nodes']\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(\"Model components restored. SVM model details:\")\n",
    "                for node, model in self.models.items():\n",
    "                    if hasattr(model, 'coef_'):\n",
    "                        print(f\"Node {node} SVM weights shape: {model.coef_.shape}\")\n",
    "                        print(f\"Node {node} SVM weights: {model.coef_}\")\n",
    "                    if hasattr(model, 'intercept_'):\n",
    "                        print(f\"Node {node} SVM intercept: {model.intercept_}\")\n",
    "            \n",
    "            # Optionally restore labels if they were saved\n",
    "            if 'all_labels' in model_data:\n",
    "                self.all_labels = model_data['all_labels']\n",
    "                if self.verbose:\n",
    "                    print(\"Labels restored from saved model\")\n",
    "            \n",
    "            print(f\"Model parameters successfully loaded from {filepath}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model parameters: {e}\")\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_10_v2_MACHI = np.load('D:\\Hierarchical Unmixing Label\\hUH\\images\\combined_10_v2_MACHI.npy')\n",
    "saturated_combined_10_v2_MACHI = np.load('D:\\Hierarchical Unmixing Label\\hUH\\images\\saturated_combined_10_v2_MACHI.npy')\n",
    "machi_tampa_2024_11_12=np.load(r'D:\\Hierarchical Unmixing Label\\hUH\\images\\tampa_2024-11-12T15-31-55Z-l1a_cm_machi.npy')\n",
    "machi_tampa_2024_11_12_labels = np.load(r'D:\\Hierarchical Unmixing Label\\hUH\\save\\machi_tampa_2024_11_12_binary_labels.npy', allow_pickle=True).item()\n",
    "combined_MACHI_labels = np.load(r'D:\\Hierarchical Unmixing Label\\hUH\\save\\combined_MACHI_binary_labels.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree1=BinaryDecisionTree(combined_MACHI_labels,verbose=True)\n",
    "tree1.load_model_parameters(r\"D:\\Hierarchical Unmixing Label\\hUH\\weights\\tree_MACHI.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree=BinaryDecisionTree(combined_MACHI_labels,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING AND EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.train(combined_10_v2_MACHI,combined_MACHI_labels)\n",
    "evaluation = tree.evaluate(combined_10_v2_MACHI,combined_MACHI_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.save_model_parameters(r\"D:\\Hierarchical Unmixing Label\\hUH\\weights\\tree_MACHI.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = tree.predict(machi_tampa_2024_11_12)\n",
    "evaluation = tree.evaluate(machi_tampa_2024_11_12,machi_tampa_2024_11_12_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.plot_input_image(machi_tampa_2024_11_12.reshape(-1,1092,112))\n",
    "tree.plot_ground_truth(machi_tampa_2024_11_12_labels, key='0000')\n",
    "tree.plot_prediction(prediction, key='0000')  \n",
    "tree.plot_ground_truth(machi_tampa_2024_11_12_labels)\n",
    "tree.plot_prediction(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hypso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
